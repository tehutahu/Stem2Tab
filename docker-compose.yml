version: "3.9"

x-backend-build: &backend-build
  context: ./backend
  dockerfile: Dockerfile
  args:
    BASE_IMAGE: pytorch/pytorch:2.4.0-cuda12.1-cudnn9-runtime
    USE_ONNXRUNTIME_GPU: "true"
    ONNXRUNTIME_GPU_VERSION: "1.20.1"
x-backend-image: &backend-image stem2tab-backend:latest

services:
  redis:
    image: redis:7.2-alpine
    command: ["redis-server", "--save", "", "--appendonly", "no"]
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 10

  api:
    image: *backend-image
    build: *backend-build
    env_file: .env
    environment:
      - FILE_BUCKET_PATH=${FILE_BUCKET_PATH:-/data}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}
      - DEMUCS_MODEL=${DEMUCS_MODEL:-htdemucs}
      - BASIC_PITCH_MODEL_SERIALIZATION=${BASIC_PITCH_MODEL_SERIALIZATION:-onnx}
      - API_PORT=${API_PORT:-8000}
      - PYTHONPATH=/app/src
      - DEMUCS_CACHEDIR=${FILE_BUCKET_PATH:-/data}/cache/demucs
      - TORCH_HOME=${FILE_BUCKET_PATH:-/data}/cache/demucs
    command:
      [
        "uvicorn",
        "src.api.main:app",
        "--host",
        "0.0.0.0",
        "--port",
        "${API_PORT:-8000}",
      ]
    volumes:
      - ./data:${FILE_BUCKET_PATH:-/data}
      - ./backend/src:/app/src
      - ./backend/tests:/app/tests
      - torch-cache:/root/.cache/torch
      - uv-cache:/root/.cache/uv
    ports:
      - "${API_PORT:-8000}:${API_PORT:-8000}"
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${API_PORT:-8000}/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  worker:
    image: *backend-image
    env_file: .env
    environment:
      - FILE_BUCKET_PATH=${FILE_BUCKET_PATH:-/data}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}
      - DEMUCS_MODEL=${DEMUCS_MODEL:-htdemucs}
      - BASIC_PITCH_MODEL_SERIALIZATION=${BASIC_PITCH_MODEL_SERIALIZATION:-onnx}
      - PYTHONPATH=/app/src
      - NVIDIA_VISIBLE_DEVICES=all
      - DEMUCS_CACHEDIR=${FILE_BUCKET_PATH:-/data}/cache/demucs
      - TORCH_HOME=${FILE_BUCKET_PATH:-/data}/cache/demucs
    command: ["celery", "-A", "src.worker.app", "worker", "-l", "info"]
    volumes:
      - ./data:${FILE_BUCKET_PATH:-/data}
      - ./backend/src:/app/src
      - ./backend/tests:/app/tests
      - torch-cache:/root/.cache/torch
      - uv-cache:/root/.cache/uv
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "celery -A src.worker.app inspect ping -d celery@$(hostname)"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  web:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    env_file: .env
    command:
      [
        "npm",
        "run",
        "preview",
        "--",
        "--host",
        "0.0.0.0",
        "--port",
        "${WEB_PORT:-4173}",
      ]
    ports:
      - "${WEB_PORT:-4173}:${WEB_PORT:-4173}"
    depends_on:
      api:
        condition: service_started

volumes:
  torch-cache:
  uv-cache:

